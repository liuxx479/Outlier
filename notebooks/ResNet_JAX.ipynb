{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train-neural-network.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMJL6Dzds4TmW7So7y6z2DK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuxx479/Outlier/blob/master/notebooks/ResNet_JAX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiUibhYRCet3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "01aa1018-66b3-41fa-c0df-b5a4513c3cde"
      },
      "source": [
        "from __future__ import print_function, division, absolute_import\n",
        "\n",
        "import numpy.random as npr\n",
        "import os\n",
        "\n",
        "import jax.numpy as np\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "import jax.numpy as np\n",
        "from jax.config import config\n",
        "from jax import jit, grad, random\n",
        "from jax.experimental import optimizers\n",
        "from jax.experimental import stax\n",
        "import tensorflow as tf\n",
        "from jax.experimental.stax import (AvgPool, BatchNorm, Conv, Dense, FanInSum,\n",
        "                                   FanOut, Flatten, GeneralConv, Identity,\n",
        "                                   MaxPool, Relu, LogSoftmax)\n",
        "\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "%pylab inline\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "!pip install --quiet git+https://github.com/liuxx479/Outlier.git\n",
        "from outlier.datasets import gaussian_convergence\n",
        "\n",
        "\n",
        "########### JL note: mostly following https://colab.research.google.com/github/google/jax/blob/master/docs/notebooks/neural_network_with_tfds_data.ipynb\n",
        "########### https://github.com/google/jax/blob/master/examples/resnet50.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['np', 'random']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for Outlier (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYH51ZKJU7d3",
        "colab_type": "code",
        "outputId": "e3f10494-fac4-4004-ef7c-4ec16d2a38e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "######### mount google drive file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "root = '/content/drive/My Drive'\n",
        "data_path = os.path.join(root,'tensorflow_datasets/')\n",
        "model_path= os.path.join(root,'models/')\n",
        "\n",
        "if not os.path.isdir(model_path):\n",
        "    os.makedirs(model_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZHqV3oFXM0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########## load data from gdrive, if need to downlaod again, set download=1\n",
        "VERSION = tfds.core.Version('0.1.0')\n",
        "dataset, info = tfds.load(name=\"gaussian_convergence\", download=0, split=\"train\", data_dir=data_path, with_info=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zginT0txXOjF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8cfc130-f152-44a8-c100-a5ca3f69642e"
      },
      "source": [
        "print ('data size:',info.splits['train'].num_examples)\n",
        "data_size=info.splits['train'].num_examples"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data size: 20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xwVxsWfVP2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for example in dataset.take(1):  #take 1 for test\n",
        "#   kappa_map, params = example[\"map\"], example[\"params\"]\n",
        "#   imshow(kappa_map)\n",
        "#   print(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPron-dAF0Vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "S8_gen= lambda params: np.sqrt(params.T[0]/0.3)*params.T[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nx6qUOoxkgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############ JL: resnet architecture, mostly unchanged, other than removed bunch of idensity matrices\n",
        "\n",
        "def ConvBlock(kernel_size, filters, strides=(2, 2)):\n",
        "  ks = kernel_size\n",
        "  filters1, filters2, filters3 = filters\n",
        "  Main = stax.serial(\n",
        "      Conv(filters1, (1, 1), strides), BatchNorm(), Relu,\n",
        "      Conv(filters2, (ks, ks), padding='SAME'), BatchNorm(), Relu,\n",
        "      Conv(filters3, (1, 1)), BatchNorm())\n",
        "  Shortcut = stax.serial(Conv(filters3, (1, 1), strides), BatchNorm())\n",
        "  return stax.serial(FanOut(2), stax.parallel(Main, Shortcut), FanInSum, Relu)\n",
        "\n",
        "def IdentityBlock(kernel_size, filters):\n",
        "  ks = kernel_size\n",
        "  filters1, filters2 = filters\n",
        "  def make_main(input_shape):\n",
        "    # the number of output channels depends on the number of input channels\n",
        "    return stax.serial(\n",
        "        Conv(filters1, (1, 1)), BatchNorm(), Relu,\n",
        "        Conv(filters2, (ks, ks), padding='SAME'), BatchNorm(), Relu,\n",
        "        Conv(input_shape[3], (1, 1)), BatchNorm())\n",
        "  Main = stax.shape_dependent(make_main)\n",
        "  return stax.serial(FanOut(2), stax.parallel(Main, Identity), FanInSum, Relu)\n",
        "\n",
        "# ResNet architectures compose layers and ResNet blocks\n",
        "def ResNet50(num_classes):\n",
        "  ########## JL to do: maybe remove some IdentityBlocks..\n",
        "  return stax.serial(\n",
        "      GeneralConv(('HWCN', 'OIHW', 'NHWC'), 64, (7, 7), (2, 2), 'SAME'),\n",
        "      BatchNorm(), \n",
        "      Relu, \n",
        "      MaxPool((3, 3), strides=(2, 2)),\n",
        "      ConvBlock(3, [64, 64, 256], strides=(1, 1)),\n",
        "      IdentityBlock(3, [64, 64]),\n",
        "      IdentityBlock(3, [64, 64]),\n",
        "      # ConvBlock(3, [128, 128, 512]),\n",
        "      # IdentityBlock(3, [128, 128]),\n",
        "      # IdentityBlock(3, [128, 128]),\n",
        "      # IdentityBlock(3, [128, 128]),\n",
        "      ConvBlock(3, [256, 256, 1024]),\n",
        "      IdentityBlock(3, [256, 256]),\n",
        "      # IdentityBlock(3, [256, 256]),\n",
        "      # IdentityBlock(3, [256, 256]),\n",
        "      # IdentityBlock(3, [256, 256]),\n",
        "      # IdentityBlock(3, [256, 256]),\n",
        "      ConvBlock(3, [512, 512, 2048]),\n",
        "      # IdentityBlock(3, [512, 512]),\n",
        "      IdentityBlock(3, [512, 512]),\n",
        "      AvgPool((7, 7)), \n",
        "      Flatten, \n",
        "      Dense(num_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGQO8HzF1Dt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from jax import random\n",
        "rng_key = random.PRNGKey(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w359K7IaLuU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(params, batch):\n",
        "  kappa_map, params_true = batch\n",
        "  params_pred = predict_fun(params, kappa_map)\n",
        "  #out1 = np.sum((S8_gen(params_pred) - S8_gen(params_true))**2) ## controls S8\n",
        "  # out2 = np.sum((params_pred - params_true)**2) ## controls individual params\n",
        "  out2 = np.mean((params_pred - params_true)**2)\n",
        "  return out2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SsrmV6paRoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########### hack from: https://github.com/google/jax/issues/2116\n",
        "from jax.tree_util import pytree\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "\n",
        "suffix = '.pickle'\n",
        "\n",
        "def savemodel(data: pytree, path: Union[str, Path], overwrite: bool = False):\n",
        "    path = Path(path)\n",
        "    if path.suffix != suffix:\n",
        "        path = path.with_suffix(suffix)\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if path.exists():\n",
        "        if overwrite:\n",
        "            path.unlink()\n",
        "        else:\n",
        "            raise RuntimeError(f'File {path} already exists.')\n",
        "    with open(path, 'wb') as file:\n",
        "        pickle.dump(data, file)\n",
        "\n",
        "\n",
        "def loadmodel(path: Union[str, Path]) -> pytree:\n",
        "    path = Path(path)\n",
        "    if not path.is_file():\n",
        "        raise ValueError(f'Not a file: {path}')\n",
        "    if path.suffix != suffix:\n",
        "        raise ValueError(f'Not a {suffix} file: {path}')\n",
        "    with open(path, 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K06x5xl_3Mw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####### prepare training sets\n",
        "\n",
        "batch_size = 64 ### number of maps per batch\n",
        "valid_size = 128 #int(0.1*data_size)\n",
        "test_size = int(0.1*data_size)\n",
        "train_size = data_size - valid_size -test_size #int(0.8*data_size)\n",
        "\n",
        "dataset.shuffle(1000)\n",
        "valid_batch = dataset.take(valid_size).batch(valid_size)\n",
        "test_batch = dataset.skip(valid_size).take(test_size).batch(test_size)\n",
        "train_batch = dataset.skip(valid_size+test_size).repeat().batch(batch_size)\n",
        "\n",
        "def preprocess(dataset, augment=1):\n",
        "  images=dataset['map']\n",
        "  images=tf.transpose(images, (1,2,0)) ##### move the batch size to last axis\n",
        "  # print ('preproess shape', images.numpy().shape)\n",
        "  if augment:\n",
        "    images=tf.image.random_flip_left_right(images)\n",
        "    images=tf.image.random_flip_up_down(images)\n",
        "    images=tf.image.rot90(images, k=randint(4)) #### rotate an image in a random angle\n",
        "  images=tf.expand_dims(images,-2) ## expand the dimension to include channel\n",
        "  # images=tf.transpose(images, (1,2,3,0))\n",
        "  # print ('post processing shape',images.numpy().shape)\n",
        "  return images.numpy(), dataset['params'].numpy()\n",
        "\n",
        "for itest in valid_batch:\n",
        "  valid_batch = preprocess(itest, augment=0)\n",
        "  valid_maps, params_valid = valid_batch\n",
        "for itest in test_batch:\n",
        "  test_batch = preprocess(itest, augment=0)\n",
        "  test_maps, params_test = test_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6-ZXGhyjwmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############ JL: batch generator\n",
        "def synth_batches():\n",
        "  for ibatch in train_batch:\n",
        "    yield preprocess(ibatch)\n",
        "\n",
        "batches = synth_batches()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdO_WMWAIYRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a6421034-d14a-43c6-e0ba-d59edb38b699"
      },
      "source": [
        "print (test_maps.shape, params_test.shape)\n",
        "print (valid_maps.shape, params_valid.shape)\n",
        "itrain_batch  = next(batches)\n",
        "print (itrain_batch[0].shape, itrain_batch[1].shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 256, 1, 2000) (2000, 2)\n",
            "(256, 256, 1, 128) (128, 2)\n",
            "(256, 256, 1, 64) (64, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhtGSHyHQgdU",
        "colab_type": "code",
        "outputId": "b666b577-bf90-4df7-ab10-c3fe20a746a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "############# JL: training\n",
        "\n",
        "num_classes = 2\n",
        "input_shape = (256, 256, 1, batch_size)\n",
        "num_steps = int(train_size/batch_size) ## number of steps per epoch\n",
        "num_epochs = 50\n",
        "step_size = 0.001\n",
        "epoch0=23\n",
        "\n",
        "init_fun, predict_fun = ResNet50(num_classes)\n",
        "# _, init_params = init_fun(rng_key, input_shape)\n",
        "######### JL to do: change to grab the newest file automatically\n",
        "fn_model=model_path+'jax_resnet_model_epoch{:0.0f}_stepsize{}.pickle'.format(epoch0, step_size/10)\n",
        "init_params = loadmodel(fn_model)\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.adam(step_size) ##### seems to work best\n",
        "# opt_init, opt_update, get_params = optimizers.adagrad(step_size) #### seems to work\n",
        "# opt_init, opt_update, get_params = optimizers.sgd(step_size) ### doesn't work well\n",
        "# opt_init, opt_update, get_params = optimizers.nesterov(step_size, mass=0.9) ### doesn't work well\n",
        "# opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=0.9) ## doesn't work well\n",
        "\n",
        "@jit\n",
        "def update(i, opt_state, batch):\n",
        "  params = get_params(opt_state)\n",
        "  return opt_update(i, grad(loss)(params, batch), opt_state)\n",
        "\n",
        "opt_state = opt_init(init_params)\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "  for istep in range(num_steps):  \n",
        "    this_batch=next(batches)\n",
        "    opt_state = update(istep, opt_state, this_batch)\n",
        "    if istep%50==0:\n",
        "      epoch_time = (time.time() - start_time)/60.0 ## minutes\n",
        "      test_NNparams = get_params(opt_state)\n",
        "      train_loss = loss(test_NNparams, this_batch)\n",
        "      valid_loss = loss(test_NNparams, valid_batch)\n",
        "      print(\"Epoch {} at {:0.2f}m, train loss: {:0.4f}, validation loss: {:0.4f}\".format(epoch+epoch0, \n",
        "                                                   epoch_time, train_loss, valid_loss))\n",
        "  fn_model=model_path+'jax_resnet_model_epoch{:0.0f}_stepsize{}.pickle'.format(epoch+epoch0, step_size)\n",
        "  savemodel(test_NNparams, fn_model,overwrite=1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 23 at 0.26m, train loss: 2777.79, validation loss: 2696.29\n",
            "Epoch 23 at 0.63m, train loss: 0.50, validation loss: 0.49\n",
            "Epoch 23 at 1.01m, train loss: 0.09, validation loss: 0.10\n",
            "Epoch 23 at 1.38m, train loss: 0.05, validation loss: 0.07\n",
            "Epoch 23 at 1.76m, train loss: 0.06, validation loss: 0.06\n",
            "Epoch 23 at 2.13m, train loss: 0.06, validation loss: 0.05\n",
            "Epoch 24 at 2.38m, train loss: 0.05, validation loss: 0.04\n",
            "Epoch 24 at 2.75m, train loss: 0.05, validation loss: 0.04\n",
            "Epoch 24 at 3.12m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 24 at 3.50m, train loss: 0.05, validation loss: 0.04\n",
            "Epoch 24 at 3.87m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 24 at 4.24m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 25 at 4.49m, train loss: 0.04, validation loss: 0.03\n",
            "Epoch 25 at 4.87m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 25 at 5.24m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 25 at 5.61m, train loss: 0.03, validation loss: 0.02\n",
            "Epoch 25 at 5.98m, train loss: 0.02, validation loss: 0.03\n",
            "Epoch 25 at 6.35m, train loss: 0.05, validation loss: 0.05\n",
            "Epoch 26 at 6.60m, train loss: 0.03, validation loss: 0.02\n",
            "Epoch 26 at 6.97m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 26 at 7.35m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 26 at 7.72m, train loss: 0.03, validation loss: 0.02\n",
            "Epoch 26 at 8.09m, train loss: 0.02, validation loss: 0.03\n",
            "Epoch 26 at 8.46m, train loss: 0.03, validation loss: 0.04\n",
            "Epoch 27 at 8.72m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 27 at 9.09m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 27 at 9.46m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 27 at 9.83m, train loss: 0.04, validation loss: 0.03\n",
            "Epoch 27 at 10.20m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 27 at 10.57m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 28 at 10.83m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 28 at 11.20m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 28 at 11.57m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 28 at 11.94m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 28 at 12.31m, train loss: 0.04, validation loss: 0.04\n",
            "Epoch 28 at 12.68m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 29 at 12.94m, train loss: 0.02, validation loss: 0.03\n",
            "Epoch 29 at 13.31m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 29 at 13.68m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 29 at 14.05m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 29 at 14.42m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 29 at 14.79m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 30 at 15.05m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 30 at 15.42m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 30 at 15.79m, train loss: 0.04, validation loss: 0.04\n",
            "Epoch 30 at 16.17m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 30 at 16.54m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 30 at 16.91m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 31 at 17.13m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 31 at 17.54m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 31 at 17.91m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 31 at 18.28m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 31 at 18.65m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 31 at 19.02m, train loss: 0.03, validation loss: 0.02\n",
            "Epoch 32 at 19.24m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 32 at 19.65m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 32 at 20.03m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 32 at 20.39m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 32 at 20.76m, train loss: 0.04, validation loss: 0.04\n",
            "Epoch 32 at 21.14m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 33 at 21.36m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 33 at 21.77m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 33 at 22.14m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 33 at 22.51m, train loss: 0.02, validation loss: 0.03\n",
            "Epoch 33 at 22.88m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 33 at 23.25m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 34 at 23.47m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 34 at 23.88m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 34 at 24.25m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 34 at 24.62m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 34 at 24.99m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 34 at 25.36m, train loss: 0.04, validation loss: 0.05\n",
            "Epoch 35 at 25.59m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 35 at 25.99m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 35 at 26.36m, train loss: 0.02, validation loss: 0.03\n",
            "Epoch 35 at 26.73m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 35 at 27.10m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 35 at 27.47m, train loss: 0.07, validation loss: 0.09\n",
            "Epoch 36 at 27.69m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 36 at 28.10m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 36 at 28.47m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 36 at 28.84m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 36 at 29.21m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 36 at 29.57m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 37 at 29.80m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 37 at 30.20m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 37 at 30.57m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 37 at 30.94m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 37 at 31.31m, train loss: 0.03, validation loss: 0.02\n",
            "Epoch 37 at 31.68m, train loss: 0.04, validation loss: 0.03\n",
            "Epoch 38 at 31.90m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 38 at 32.30m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 38 at 32.67m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 38 at 33.05m, train loss: 0.03, validation loss: 0.02\n",
            "Epoch 38 at 33.42m, train loss: 0.07, validation loss: 0.05\n",
            "Epoch 38 at 33.79m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 39 at 34.01m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 39 at 34.41m, train loss: 0.02, validation loss: 0.03\n",
            "Epoch 39 at 34.78m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 39 at 35.15m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 39 at 35.52m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 39 at 35.89m, train loss: 0.23, validation loss: 0.21\n",
            "Epoch 40 at 36.12m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 40 at 36.52m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 40 at 36.89m, train loss: 0.02, validation loss: 0.03\n",
            "Epoch 40 at 37.26m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 40 at 37.63m, train loss: 0.04, validation loss: 0.04\n",
            "Epoch 40 at 38.00m, train loss: 0.19, validation loss: 0.17\n",
            "Epoch 41 at 38.22m, train loss: 0.04, validation loss: 0.04\n",
            "Epoch 41 at 38.62m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 41 at 39.00m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 41 at 39.37m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 41 at 39.74m, train loss: 0.04, validation loss: 0.03\n",
            "Epoch 41 at 40.11m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 42 at 40.33m, train loss: 0.03, validation loss: 0.04\n",
            "Epoch 42 at 40.73m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 42 at 41.10m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 42 at 41.48m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 42 at 41.85m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 42 at 42.22m, train loss: 0.12, validation loss: 0.10\n",
            "Epoch 43 at 42.44m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 43 at 42.85m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 43 at 43.22m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 43 at 43.59m, train loss: 0.03, validation loss: 0.02\n",
            "Epoch 43 at 43.96m, train loss: 0.03, validation loss: 0.02\n",
            "Epoch 43 at 44.33m, train loss: 0.20, validation loss: 0.18\n",
            "Epoch 44 at 44.56m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 44 at 44.96m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 44 at 45.33m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 44 at 45.70m, train loss: 0.04, validation loss: 0.04\n",
            "Epoch 44 at 46.07m, train loss: 0.05, validation loss: 0.05\n",
            "Epoch 44 at 46.44m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 45 at 46.66m, train loss: 0.05, validation loss: 0.05\n",
            "Epoch 45 at 47.06m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 45 at 47.43m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 45 at 47.80m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 45 at 48.17m, train loss: 0.07, validation loss: 0.07\n",
            "Epoch 45 at 48.54m, train loss: 0.04, validation loss: 0.03\n",
            "Epoch 46 at 48.76m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 46 at 49.16m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 46 at 49.54m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 46 at 49.91m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 46 at 50.28m, train loss: 0.06, validation loss: 0.06\n",
            "Epoch 46 at 50.65m, train loss: 0.04, validation loss: 0.04\n",
            "Epoch 47 at 50.87m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 47 at 51.27m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 47 at 51.64m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 47 at 52.01m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 47 at 52.38m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 47 at 52.76m, train loss: 0.04, validation loss: 0.04\n",
            "Epoch 48 at 52.98m, train loss: 0.02, validation loss: 0.03\n",
            "Epoch 48 at 53.38m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 48 at 53.75m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 48 at 54.12m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 48 at 54.49m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 48 at 54.86m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 49 at 55.09m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 49 at 55.49m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 49 at 55.86m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 49 at 56.23m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 49 at 56.60m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 49 at 56.97m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 50 at 57.20m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 50 at 57.60m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 50 at 57.98m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 50 at 58.34m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 50 at 58.72m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 50 at 59.09m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 51 at 59.31m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 51 at 59.71m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 51 at 60.08m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 51 at 60.45m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 51 at 60.82m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 51 at 61.19m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 52 at 61.41m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 52 at 61.82m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 52 at 62.19m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 52 at 62.56m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 52 at 62.93m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 52 at 63.30m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 53 at 63.52m, train loss: 0.03, validation loss: 0.03\n",
            "Epoch 53 at 63.93m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 53 at 64.30m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 53 at 64.67m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 53 at 65.05m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 53 at 65.42m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 54 at 65.64m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 54 at 66.04m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 54 at 66.41m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 54 at 66.78m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 54 at 67.16m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 54 at 67.53m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 55 at 67.75m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 55 at 68.15m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 55 at 68.52m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 55 at 68.89m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 55 at 69.27m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 55 at 69.64m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 56 at 69.86m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 56 at 70.26m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 56 at 70.63m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 56 at 71.00m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 56 at 71.38m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 56 at 71.75m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 57 at 71.97m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 57 at 72.37m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 57 at 72.74m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 57 at 73.12m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 57 at 73.49m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 57 at 73.86m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 58 at 74.08m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 58 at 74.48m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 58 at 74.86m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 58 at 75.23m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 58 at 75.60m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 58 at 75.97m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 59 at 76.19m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 59 at 76.60m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 59 at 76.97m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 59 at 77.34m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 59 at 77.72m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 59 at 78.09m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 60 at 78.31m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 60 at 78.72m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 60 at 79.09m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 60 at 79.46m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 60 at 79.83m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 60 at 80.20m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 61 at 80.42m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 61 at 80.83m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 61 at 81.20m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 61 at 81.57m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 61 at 81.95m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 61 at 82.32m, train loss: 0.02, validation loss: 0.03\n",
            "Epoch 62 at 82.54m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 62 at 82.94m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 62 at 83.32m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 62 at 83.69m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 62 at 84.06m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 62 at 84.43m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 63 at 84.65m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 63 at 85.06m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 63 at 85.43m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 63 at 85.81m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 63 at 86.18m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 63 at 86.56m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 64 at 86.78m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 64 at 87.19m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 64 at 87.56m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 64 at 87.93m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 64 at 88.31m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 64 at 88.68m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 65 at 88.91m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 65 at 89.31m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 65 at 89.68m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 65 at 90.06m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 65 at 90.43m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 65 at 90.80m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 66 at 91.03m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 66 at 91.43m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 66 at 91.81m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 66 at 92.18m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 66 at 92.55m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 66 at 92.92m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 67 at 93.14m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 67 at 93.55m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 67 at 93.92m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 67 at 94.30m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 67 at 94.67m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 67 at 95.04m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 68 at 95.27m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 68 at 95.67m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 68 at 96.04m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 68 at 96.42m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 68 at 96.79m, train loss: 0.01, validation loss: 0.02\n",
            "Epoch 68 at 97.16m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 69 at 97.39m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 69 at 97.79m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 69 at 98.16m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 69 at 98.54m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 69 at 98.91m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 69 at 99.28m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 70 at 99.50m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 70 at 99.90m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 70 at 100.28m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 70 at 100.65m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 70 at 101.02m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 70 at 101.39m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 71 at 101.61m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 71 at 102.02m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 71 at 102.39m, train loss: 0.02, validation loss: 0.02\n",
            "Epoch 71 at 102.77m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 71 at 103.14m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 71 at 103.51m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 72 at 103.73m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 72 at 104.14m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 72 at 104.51m, train loss: 0.02, validation loss: 0.01\n",
            "Epoch 72 at 104.88m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 72 at 105.25m, train loss: 0.01, validation loss: 0.01\n",
            "Epoch 72 at 105.63m, train loss: 0.01, validation loss: 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuUrtvAgPpa3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "6b746e19-2c80-4480-b60a-e6f66ab37268"
      },
      "source": [
        "test_NNparams = loadmodel(fn_model)\n",
        "\n",
        "params_pred = predict_fun(test_NNparams, valid_maps)\n",
        "params_input = params_valid\n",
        "true_s8=S8_gen(params_valid)\n",
        "pred_s8=S8_gen(params_pred)\n",
        "\n",
        "figure(figsize=(14,4))\n",
        "subplot(1,3,1)\n",
        "scatter(params_input.T[0], params_input.T[1],color='r')\n",
        "title('input parameters')\n",
        "xlabel('om')\n",
        "ylabel('sigma8')\n",
        "subplot(1,3,2)\n",
        "scatter(params_pred.T[0], params_pred.T[1],color='b')\n",
        "title('output parameters')\n",
        "xlabel('om')\n",
        "ylabel('sigma8')\n",
        "subplot(1,3,3)\n",
        "scatter(true_s8, pred_s8, color='k')\n",
        "xlabel('input S8')\n",
        "ylabel('predicted S8')\n",
        "ylim(0,1)\n",
        "title('comparison')\n",
        "plt.tight_layout()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ffEbGOb8Ce2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############ check  parameter shape\n",
        "# j=0\n",
        "# for iparam in trained_params:\n",
        "#   print ('layer:',j, '/ parameter shape:', array(iparam).shape)\n",
        "#   #print (iparam)\n",
        "#   j+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88O_83W1TTR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############# test data save and restart - pass\n",
        "# step_size=0.01\n",
        "# opt_init, opt_update, get_params = optimizers.adam(step_size) ##### seems to work best\n",
        "\n",
        "# _, init_params = init_fun(rng_key, input_shape)\n",
        "# savemodel(init_params, model_path+'test2')\n",
        "# testmodel = loadmodel(model_path+'test2.pickle')\n",
        "# opt_init(testmodel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIsGpz5SLQK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########## test file save -- pass ############\n",
        "## saved as npy, and can be loaded and use as model prediction directly\n",
        "# np.save(model_path+'test', test_params)\n",
        "# test_model = np.load(model_path+'test.npy',allow_pickle=1)\n",
        "# loss(test_model, this_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00VJ2TzkaqxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########### test generator output shape - pass\n",
        "# final_NNparams = get_params(opt_state)\n",
        "# np.save(model_path+'resnet_params_{:.0f}epochs_{:.2f}stepsize.npy'.format(epoch+1, step_size), final_NNparams)\n",
        "\n",
        "# predictions = predict_fun(final_NNparams, kappa_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpGM1HQq8YUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}